plot(density(craig))
plot(density(craig), main="Mark Distribution")
lines(density(mitchum),col="red")
plot(density(craig), main="Mark Distribution",ylim=c(0,0.2))
lines(density(mitchum),col="red")
plot(density(craig), main="Mark Distribution",ylim=c(0,0.15))
lines(density(mitchum),col="red")
5100/227
51/108
53/180
17/30
install.packages("rdgal")
install.packages("shiny")
devtools::install_github("https://github.com/WayneGitShell/GWSDAT/tree/v3.11")
devtools::install_github("https://github.com/WayneGitShell/GWSDAT/tree/v3.11")
17/36
51/90
ls -l /Library/Frameworks/R.framework/Versions/
load(url("https://github.com/UofGAnalyticsData/R/blob/main/Week%203/children_classes.RData?raw=true"))
head(children)
load(url("https://github.com/UofGAnalyticsData/R/blob/main/Week%203/patients_weights.RData?raw=true"))
library(DBI)                                     # Load required packages
library(RSQLite)
con <- dbConnect(RSQLite::SQLite(), ":memory:")  # Connect to temporary database
library(babynames)                               # Load data package
dbWriteTable(con, "babynames", babynames)        # Store data in database
dbListTables(con)                                # List tables in database
dbListFields(con, "babynames")                   # List variables in babynames table
result <- dbSendQuery(con, "SELECT * FROM babynames WHERE year = 2015 ORDER By prop DESC")
# Send a query to the database
result.data <- dbFetch(result)                   # Fetch the data
dbClearResult(result)                            # Free up resources again
# Data is now in R in data frame result.data
head(result.data)                                # Print top 6 observations from data frame
dbDisconnect(con)                                # Disconnect from the database
library(jsonlite)                               # Load required package
uri <- "https://api.tfl.gov.uk/line/mode/tube/status"
data <- read_json(uri,  simplifyVector = FALSE) # Download data and convert
for (line in data) {                            # We'll learn about loops later
cat("Disruptions on",line$name,"\n")
print(line$disruptions)                       # Most of the time there are none
}
load("/Users/Craig/OneDrive - University of Glasgow/R Programming/2020-2021/Lecture Material/Week 3/addresses.RData")
addresses
dim(addresses)
length(addresses)
load("/Users/Craig/OneDrive - University of Glasgow/R Programming/2019-2020/Assignment 1/a1.RData")
load(url("http://www.stats.gla.ac.uk/~levers/rp/t2.RData"))
?load
a <- 1
a
a <- 2
a
a <- 1
a
a <- 2
a
a <- 1
a <- 2
a <- 1
a <- 2
a <- 1
a <- 2
for weekday in (c("Mon","...","Sun")) {
print(weekday)
}
for weekday in (("Mon","...","Sun")) {
print(weekday)
}
source('~/.active-rstudio-document', echo=TRUE)
2/3*2
2/(3*2)
1/0
Inf/Inf
sqrt(-2)
sqrt(-2+0i)
a <- 5
b <- a/2
b
a <- 5
b <- a/2
b
a <- 10
b
ls()
install.packages("learnr")
devtools::install_github("RamiKrispin/coronavirus")
library(coronavirus)
coronavirus::coronavirus
mtcars2 <- mtcars %>%
transform(lp100k=235.21/mpg) %>%
subset(lp100k<=10)
library(tidyverse)
mtcars2 <- mtcars %>%
transform(lp100k=235.21/mpg) %>%
subset(lp100k<=10)
mtcars %>%
transform(lp100k=235.21/mpg) %>%
subset(lp100k<=10) %$%
cor(disp, hp)
mtcars %>%
transform(lp100k=235.21/mpg) %>%
subset(lp100k<=10) %>%
cor(disp, hp)
library(magrittr)
mtcars %>%
transform(lp100k=235.21/mpg) %>%
subset(lp100k<=10) %$%
cor(disp, hp)
starships
library(dplyr)
starwars
long <- data.frame(patients=c("John","John","Mary","Mary"),
when=c("before",'after','before','after'),
heartrate=c(85,70,78,66))
long
wide <- data.frame(patients=c('John','Mary'),before=c(85,78),
after=c(70,66))
wids
wide
long %>%
spread(when,heartrate)
wide %>%
gather(when,heartrate,patients)
wide %>%
gather(when,heartrate,-patients)
wide
load(url(paste("https://github.com/UofGAnalyticsData/R/raw/",
"main/Week%204/EURef.RData",sep="")))
wards_extended <- wards %>%
inner_join(genelec,by="ConstituencyCode",
suffix=c("Ward","Const")) %>%
mutate(ConVote=ConVote/ElectorateConst*ElectorateWard,
LabVote=LabVote/ElectorateConst*ElectorateWard,
LDVote=LDVote/ElectorateConst*ElectorateWard,
UKIPVote=UKIPVote/ElectorateConst*ElectorateWard,
GreenVote=GreenVote/ElectorateConst*ElectorateWard,
TotalVote=TotalVote/ElectorateConst*ElectorateWard,)
wards_extended
dim(wards)
dim(wards_extended)
dim(genelec)
la_shares <- wards_extended %>%
group_by(LACode) %>%
summarise(ConVote = sum(ConVote)/sum(TotalVote),
LabVote=sum(LabVote)/sum(TotalVote),
LDVote=sum(LDVote)/sum(TotalVote),
UKIPVote=sum(UKIPVote)/sum(TotalVote),
GreenVote=sum(GreenVote)/sum(TotalVote))
la_shares
sum(la_shares[1,])
sum(la_shares[1,-1])
sum(la_shares[2,-1])
sum(la_shares[3,-1])
sum(la_shares[4,-1])
sum(la_shares[5,-1])
wards_extended <- wards %>%
inner_join(genelec, by="ConstituencyCode",
suffix=c("Ward","Const")) %>%
mutate(ConVote=ConVote/ElectorateConst*ElectorateWard,
LabVote=LabVote/ElectorateConst*ElectorateWard,
LDVote=LDVote/ElectorateConst*ElectorateWard,
UKIPVote=UKIPVote/ElectorateConst*ElectorateWard,
GreenVote=GreenVote/ElectorateConst*ElectorateWard,
TotalVote=TotalVote/ElectorateConst*ElectorateWard)
la_shares <- wards_extended %>%
group_by(LACode) %>%
summarise(ConVote=sum(ConVote)/sum(TotalVote),
LabVote=sum(LabVote)/sum(TotalVote),
LDVote=sum(LDVote)/sum(TotalVote),
UKIPVote=sum(UKIPVote)/sum(TotalVote),
GreenVote=sum(GreenVote)/sum(TotalVote))
la_shares
sum(la_shares[5,-1])
qplot(UKIPvote,Leave,data=brexit %>% inner_join(la_shares))
wards_extended <- wards %>%
inner_join(genelec, by="ConstituencyCode",
suffix=c("Ward","Const")) %>%
mutate_at(vars(ConVote:TotalVote),
funs(./ElectorateConst*ElectorateWard))
la_shares <- wards_extended %>%
group_by(LACode) %>%
summarise_at(vars(ConVote:GreenVote),
funs(sum(.)/sum(TotalVote)))
qplot(UKIPvote,Leave,data=brexit %>% inner_join(la_shares))
wards_extended <- wards %>%
inner_join(genelec,by="ConstituencyCode",
suffix=c("Ward","Const")) %>%
mutate(ConVote=ConVote/ElectorateConst*ElectorateWard,
LabVote=LabVote/ElectorateConst*ElectorateWard,
LDVote=LDVote/ElectorateConst*ElectorateWard,
UKIPVote=UKIPVote/ElectorateConst*ElectorateWard,
GreenVote=GreenVote/ElectorateConst*ElectorateWard,
TotalVote=TotalVote/ElectorateConst*ElectorateWard)
la_shares <- wards_extended %>%
group_by(LACode) %>%
summarise(ConVote = sum(ConVote)/sum(TotalVote),
LabVote=sum(LabVote)/sum(TotalVote),
LDVote=sum(LDVote)/sum(TotalVote),
UKIPVote=sum(UKIPVote)/sum(TotalVote),
GreenVote=sum(GreenVote)/sum(TotalVote))
qplot(UKIPVote,Leave,data=brexit %>% inner_join(la_shares))
load(url(paste("https://github.com/UofGAnalyticsData/R/raw/",
"main/Week%204/EURef.RData",sep="")))
library(tidyverse)
library(magrittr)
x <- rnorm(100)
mean(x)
mean(rnorm(100))
rnorm(100) %>%
mean()
View(mtcars)
mtcars2 <- mtcars %>%
transform(lp100k=235.21/mpg) $>$
subset(lp100k <= 10)
mtcars2 <- mtcars %>%
transform(lp100k=235.21/mpg) %>%
subset(lp100k <= 10)
cor(mtcars2$disp,mtcars2$hp)
mtcars %>%
transform(lp100k=235.21/mpg) %>%
subset(lp100k <= 10) %$%
cor(disp,hp)
mtcars %<>%
transform(lp100k=235.21/mpg) %>%
subset(lp100k <= 10)
View(mtcars)
long
long <- data.frame(patients=c("John","John","Mary","Mary"),
when=c("before",'after','before','after'),
heartrate=c(85,70,78,66))
long
wide <- data.frame(patients=c('John','Mary'),before=c(85,78),
after=c(70,66))
wide
long %>%
spread(when,heartrate)
wide %>%
gather(when,heartrate,-patients)
load(url("https://github.com/UofGAnalyticsData/R/raw/main/Week%204/velib"))
load(url("https://github.com/UofGAnalyticsData/R/raw/main/Week%205/w5.RData"))
library(tidyverse)
?lag
funs()
?plot
n <- 25
x <- rnorm(n)
y <- rnorm(n)
plot(x,y)
plot(y~x)
View(health)
plot(LifeExpectancy~HealthExpenditure,data=health)
plot(LifeExpectancy~HealthExpenditure,data=health,col=1+unclass(Region))
legend("bottomright",pch=1,col=1+unclass(Region),legend=levels(Region))
legend("bottomright",pch=1,col=1+unclass(Region),legend=levels(health$Region))
legend("bottomright",pch=1,col=1+unclass(health$Region),legend=levels(health$Region))
names(height) <- c("one","two","three","four")
height <- 1:4
names(height) <- c("one","two","three","four")
barplot(height)
barplot(height,col=rainbow(4))
library(magrittr)
health %$%
table(Region) %>%
pie()
health %$% hist(LifeExpectancy)
health %$% hist(LifeExpectancy,breaks=20)
health %$% hist(LifeExpectancy,breaks=5)
health %$% hist(LifeExpectancy,breaks=3)
health %$% plot(density(LifeExpectancy))
pairs(health[,4:6])
n <- 1000
x <- runif(n,0,2*pi)
x <- sort(x)
y <- sin(x)
y.noisy <- y + .25*rnorm(n)
plot(x,y.noisy)
lines(x,y,col=2)
par(mfrow=c(2,1))
plot(x,sin(x),type="l")
par(mfrow=c(1,2))
plot(x,sin(x),type="l")
plot(x,cos(x),type="l")
A <- rbind(c(1, 5, 7),
c(2, 4, 2),
c(9, 0, 6))
A
cbind(c(1, 2, 9)
c(5, 4, 0)
c(7, 2, 6))
cbind(c(1,2,9),
c(5,4,0),
c(7,2,6))
cbind(c(1, 2, 9),c(5, 4, 0),c(7, 2, 6))
cbind(c(1,2,9),c(5,4,0),c(7,2,6))
cbind(c(1, 2, 9),
c(5, 4, 0),
c(7, 2, 6))
cbind(c(1, 2, 9), c(5, 4, 0), c(7,2,6))
cbind(c(1,2,9),c(5,4,0),c(7,2,6))
cbind(c(0, 2, 4),
c(1, 0, 2),
c(3, 2, 1))
rbind(c(0,1,3),c(2,0,2),c(4,2,1))
rbind(c(0,1,3), c(2,0,2), c(4,2,1))
rbind(c(0, 1, 3), c(2, 0, 2), c(4, 2, 1))
rbind(c(0,1,3),c(2,0,2),c(4,2,1))
rbind(c(0, 1, 3),
c(2, 0, 2),
c(4, 2, 1))
rbind(c(0,1,3),
c(2,0,2),
c(4,2,1))
rbind(c(0, 1, 3),
c(2, 0, 2),
c(4, 2, 1))
rbind(c(0,1,3),
c(2,0,2),
c(4,2,1))
rbind(c(3, 0, 0, 0),
c(0, 1, 0, 0),
c(0, -1, 3, 0),
c(0, 0, 0, 1))
A <- diag(c(3,1,3,1),nrow=4,ncol=4)
A[3,2] <- -1
A
A <- diag(c(3,1,3,1))
A[3,2]<- -1
A
A<- diag(c(3, 1, 3, 1))   #Create matrix using diag
A[3,2] <- -1              #Amend element manually
A
A <- diag(c(2, 4, 6))
A[1,3] <- 5
A
rbind (c(2,0,5), c(0,4,0), c(0,0,6))
rbind(c(2,0,5), c(0,4,0), c(0,0,6))
rbind(c(2, 0, 5),
c(0, 4, 0),
c(0, 0, 6))
rbind(c(2,0,5), c(0,4,0), c(0,0,6))
setwd("~/Documents/GitHub/R/Assignment 1")
read.csv("potus.csv", header=TRUE, sep=";")
read.csv('potus.csv',sep=';')
read.csv(url(paste("https://github.com/UofGAnalyticsData/R/raw/main/Assignment%201/potus.csv")),sep=";",na.strings = "NA")
read.table(url("https://github.com/UofGAnalyticsData/R/raw/main/Assignment%201/potus.csv"), sep=";", na.strings="NA", header=TRUE)
?read.table
read.table("potus.txt",header = TRUE, sep = " ")
read.table(url("https://github.com/UofGAnalyticsData/R/raw/main/Assignment%201/potus.txt"), header=TRUE, sep=" ", na.strings="*")
read.table("potus.txt", header=TRUE, na.strings="*")
read.table("/Users/Adil/Downloads/potus.txt", header=TRUE, sep=" ", na.strings="*")
read.table("potus.txt", header=TRUE, sep=" ", na.strings="*")
read.csv("potus.txt",fill=TRUE,header=TRUE)
x <- read.csv("potus.csv", header = TRUE, sep = ";", na.strings = "NA")
is.na(x)
table(is.na(x))
?read.csv
read.csv(file = "flow.txt",na.strings = "-")
read.csv("C:/Users/elean/OneDrive/MDataGov/R Programming/data/Prog Quiz 1/flow.csv", na.strings="-")
read.csv("flow.csv", na.strings="-")
n <- 10000
arrival <- 35+rexp(n, rate=0.2)
departure <- 40+rexp(n, rate=0.2)
length(late[arrival>departure]) #count the number of times I would have missed the train
length(late[arrival>departure])/n  #The proportion of times I would have missed the train
n <- 10000
arrival <- 35+rexp(n, rate=0.2)
departure <- 40+rexp(n, rate=0.2)
late.count <- sum(arrival > departure)
late.proportion <- late.count/n
late.proportion
arrival
length(which(arrival>=departure))
## Probability missing train is count of missed days/total days (length of either arrival or departure vector). 1845/10000
length(which(arrival>=departure))/length(departure)
n <- 10000
arrival <- 35+rexp(n, rate=0.2)
departure <- 40+rexp(n, rate=0.2)
missed <- sum(departure<arrival, na.rm="TRUE")
proportion.missed <- missed/length(departure)
proportion.missed
n <- 10000
arrival <- 35+rexp(n, rate=0.2)
departure <- 40+rexp(n, rate=0.2)
length(which(departure>40.0))
pexp(40,rate=0.2,lower.tail = TRUE)
sum(departure < arrival)
T<-(departure-arrival)
T<=0 #if T<=0 it means that I would miss the train
miss<-sum(T<=0) #number of replications for missed train
missed740_prop=miss/n  #prop of times missed 7:40 train
missed740_prop
n <- 10000
coffee <- rnorm(n, 50, 15)
milk <- rnorm(n, 175, 15)
# number of times that mug would spill over
spill_n <- coffee + milk
spill_260 <- spill_n > 260
sum_spill <- sum(spill_260 == "TRUE")
# proportion of number of times it spills compared to total number of refills
proportion_spills <- sum_spill/n
proportion_spills
MilkCoffee <- coffee + milk
# Count for how many of the replications your mug of coffee #(with milk) would spill over:
sum(MilkCoffee>260)
#  Calculate the proportion of times your coffee (with milk) # would spillover (this is an estimate of the corresponding # probability).
sum(MilkCoffee>260)/n
spill_over <- (milk + coffee)>260
#Count for how many of the replications your mug of coffee (with milk) would spill over
spill_over_count <- length(subset(spill_over,spill_over==TRUE))
#Calculate the proportion of times your coffee (with milk) would spill over
(spill_over_count/n)
total_vol<-coffee+milk
num_spills<-sum(total_vol>260) # assuming that it doesn't spill if it's exactly 260ml
prop_spills<-num_spills/n
prop_spills
sum(coffee+milk > 260)     # times the coffee with milk spills over
sum(coffee+milk > 260)/n
n <- 10000
mugCapacity <- 260 #Mug can hold 260ml of liquid
coffee <- rnorm(n, 50, 15)
milk <- rnorm(n, 175, 15)
spillOverProbability <- sum((coffee + milk) > mugCapacity)/n
cat("The proportion of times the mug would spill over is:",spillOverProbability)
n <- 10000
friend.1 <- runif(n, 0, 60)
friend.2 <- runif(n, 0, 60)
meetings <- abs(friend.1-friend.2) <= 15  #Is their arrival time within 15 minutes of each other
length(meetings[meetings == TRUE]) #number of times they would have managed to meet
length(meetings[meetings == TRUE])/n #proportion of times they would have met (successful meetings/total meetings)
sum(abs(friend.1-friend.2)<=15)
# Proportion of times that the friends would manage to meet up
sum(abs(friend.1-friend.2)<=15)/n
friend.1.leave <- friend.1+15 #Create vector of friend 1 leaving time
friend.2.leave <- friend.2.leave+15 #Create vector of friend 2 leaving time
friend.time <-  (friend.2<= friend.1 & friend.1<= friend.2.leave)|(friend.1<=friend.2& friend.2<=friend.1.leave) #Create logic vector for TRUE when friends meet (friend 1 must arrive after friend 2 arrives and before friend 2 leaves and vice versa)
sum(friend.time)#count number of times TRUE is in vector of friend.time
sum(friend.time/n) #Divide by number of replications to get probability estimate
friend.1.leave <- friend.1+15 #Create vector of friend 1 leaving time
friend.2.leave <- friend.2.leave+15 #Create vector of friend 2 leaving time
friend.time <-  (friend.2<= friend.1 & friend.1<= friend.2.leave)|(friend.1<=friend.2& friend.2<=friend.1.leave) #Create logic vector for TRUE when friends meet (friend 1 must arrive after friend 2 arrives and before friend 2 leaves and vice versa)
sum(friend.time)#count number of times TRUE is in vector of friend.time
sum(friend.time/n) #Divide by number of replications to get probability estimate
friend.1.leave <- friend.1+15 #Create vector of friend 1 leaving time
friend.2.leave <- friend.2+15 #Create vector of friend 2 leaving time
friend.time <-  (friend.2<= friend.1 & friend.1<= friend.2.leave)|(friend.1<=friend.2& friend.2<=friend.1.leave) #Create logic vector for TRUE when friends meet (friend 1 must arrive after friend 2 arrives and before friend 2 leaves and vice versa)
sum(friend.time)#count number of times TRUE is in vector of friend.time
sum(friend.time/n) #Divide by number of replications to get probability estimate
sum(abs(friend.1-friend.2)<=15)
# Proportion of times that the friends would manage to meet up
sum(abs(friend.1-friend.2)<=15)/n
meetup <- sum(abs(friend.1-friend.2)<=15) # number of times they meet up
meet.prop <- meetup/n # proportion of times they would managed to meet
meet.prop
n <- 10000
friend.1 <- runif(n,0,60)
friend.2 <- runif(n,0,60)
meet_count <- 0
probability_estimate <- 0
wait_time <- 15
for (n in seq(1,10000)){
if (abs(friend.1[n] - friend.2[n]) <= wait_time){
meet_count = meet_count + 1
}
}
meet_count
probability_estimate <- meet_count/n
probability_estimate
N <- sum(abs(friend.1 - friend.2)<=15)
print(N)
#N over total obs = probability
P <- N/10000
print (P)
df <- cbind(friend.1,friend.2)
df <- as.data.frame(df)
head(df)
df$friend.1_plus_15 <- df$friend.1+15
df$friend.2_plus_15 <- df$friend.2+15
head(df)
df$met_unmet <- df$friend.1_plus_15 - df$friend.2
df$met_unmet_2 <- df$friend.2_plus_15 - df$friend.1
head(df)
met_1 <- df[df$friend.1<df$friend.2&df$met_unmet>0&df$met_unmet<=15,]
df[df$friend.1_plus_15-df$friend.2>0,]
met_2 <- df[df$friend.2>df$friend.1&df$met_unmet_2>0&df$met_unmet<=15,]
str(df)
no_of_replications <- nrow(met_2) + nrow(met_1)
Pro_of_meetups <- no_of_replications/n
Pro_of_meetups
met_1
met_1
dim(met_!)
dim(met_1)
dim(met_2)
# friend 2 arrives first
# check whether friend.1 arrives within 15 minute window of friend.2
check1 <- friend.2 <= friend.1 & friend.1 <= friend.2+15
# friend 1 arrives first
# check whether friend.2 arrives within 15 minute window of friend.1
check2 <- friend.1 <= friend.2 & friend.2 <= friend.1+15
# check if friends do meet (either one of the two conditions has to be true)
checkMeating <- check1 | check2
# count the TRUE's, in the sum they all give a 1. FALSE gives 0
numberOfMeatingReplications <- sum(checkMeating)
numberOfMeatingReplications
# divide by total replications
proportion <- numberOfMeatingReplications/n
proportion
meet <- sum(abs(friend.2-friend.1)<=15) #number of times they can meet
prob <- meet/n  #proportion of times they can meet
pron
prob
